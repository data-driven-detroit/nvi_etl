{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edd49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "from nvi_etl import setup_logging\n",
    "from nvi_etl.geo_reference import (\n",
    "    pull_city_boundary, pull_council_districts, pull_zones\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for indicator_id, indicator_details in indicator_map[\"indicators\"].items():\n",
    "    # For now every respondent is in the universe, but this may change in the future\n",
    "    universe = pd.Series(True, range(len(recoded)))\n",
    "\n",
    "    # Count any respondent who meets the criteria\n",
    "    count = pd.concat(\n",
    "        [\n",
    "            recoded[question_details[\"column\"]].isin(question_details[\"options\"][\"values\"])\n",
    "            for _, question_details in indicator_details[\"questions\"].items()\n",
    "        ], axis=1\n",
    "    ).any(axis=1) & universe # but include people who are in the universe\n",
    "\n",
    "    indicator_cols = (\n",
    "        recoded[[\"Response ID\"]] # Leave as a one column Dataframe\n",
    "        .assign(\n",
    "            **{\n",
    "                f\"universe_{indicator_id}\": universe,\n",
    "                f\"count_{indicator_id}\": count\n",
    "            }\n",
    "        )\n",
    "        .set_index(\"Response ID\")\n",
    "    )\n",
    "\n",
    "    columns.append(indicator_cols)\n",
    "\n",
    "complete = pd.concat(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825df556",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = pd.concat(\n",
    "    [\n",
    "        (\n",
    "            complete\n",
    "            .join(\n",
    "                recoded[[\"Response ID\", \"citywide\"]]\n",
    "                .set_index(\"Response ID\")\n",
    "            )\n",
    "            .rename(columns={\"citywide\": \"location_id\"})\n",
    "            .groupby(\"location_id\")\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        ),\n",
    "        (\n",
    "            complete\n",
    "            .join(\n",
    "                recoded[[\"Response ID\", \"district\"]].set_index(\"Response ID\")\n",
    "            )\n",
    "            .rename(columns={\"district\": \"location_id\"})\n",
    "            .groupby(\"location_id\")\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        ),\n",
    "        (\n",
    "            complete\n",
    "            .join(\n",
    "                recoded[[\"Response ID\", \"zone\"]].set_index(\"Response ID\")\n",
    "            )\n",
    "            .rename(columns={\"zone\": \"location_id\"})\n",
    "            .groupby(\"location_id\")\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        ),\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "long_file = pd.wide_to_long(\n",
    "    aggregations,\n",
    "    stubnames=[\"count\", \"universe\"],\n",
    "    i=\"location_id\",\n",
    "    j=\"indicator_id\",\n",
    "    sep=\"_\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9001463",
   "metadata": {},
   "source": [
    "# Working out using new data dictionary setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b685eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cbb599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "normalized_data_dictionary = pd.read_excel(Path.cwd() / \"conf\" / \"normalized_data_dict.xlsx\")\n",
    "recoded = pd.read_csv(Path.cwd() / \"output\" / \"nvi_2024_analysis_source.csv\", low_memory=False)\n",
    "\n",
    "reconstructed_columns = set()\n",
    "for _, row in normalized_data_dictionary.iterrows():\n",
    "    question = row[\"question\"]\n",
    "    answer = row[\"answer\"]\n",
    "    group = row[\"group\"]\n",
    "\n",
    "    if row[\"multiselect\"] and (group != question) and (question != answer):\n",
    "        # Grid of death\n",
    "        new_col = \":\".join((answer, question, group))\n",
    "        if new_col not in reconstructed_columns:\n",
    "            reconstructed_columns.add(new_col)\n",
    "\n",
    "\n",
    "    elif (group == question):\n",
    "        # Ungrouped single-select questions\n",
    "        if question not in reconstructed_columns:\n",
    "            reconstructed_columns.add(question)\n",
    "\n",
    "\n",
    "    elif not row[\"multiselect\"]:\n",
    "        # Likert / other single-select\n",
    "        new_col = \":\".join((question, group))\n",
    "        if new_col not in reconstructed_columns:\n",
    "            reconstructed_columns.add(new_col)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Grouped multi-select\n",
    "        new_col = \":\".join((answer, group))\n",
    "        if new_col not in reconstructed_columns:\n",
    "            reconstructed_columns.add(new_col)\n",
    "\n",
    "\n",
    "ignore_columns = [\n",
    "    'Response ID',\n",
    "    'Time Started',\n",
    "    'Date Submitted',\n",
    "    'Status',\n",
    "    'Contact ID',\n",
    "    'Legacy Comments',\n",
    "    'Comments',\n",
    "    'Language',\n",
    "    'Referer',\n",
    "    'SessionID',\n",
    "    'User Agent',\n",
    "    'Tags',\n",
    "    'IP Address',\n",
    "    'Longitude',\n",
    "    'Latitude',\n",
    "    'Country',\n",
    "    'City',\n",
    "    'State/Region',\n",
    "    'Postal',\n",
    "    'By selecting this box, I confirm that I am at least 18 years old, that my primary residence is in the City of Detroit, and that I have read and understand the above information.:Confirm_18_Resident_Consent',\n",
    "    'Detroit_Residence_Address',\n",
    "    'Detroit_Residence_ZipCode',\n",
    "    'Geocode_address',\n",
    "    'Geocode_zip',\n",
    "    'City_D',\n",
    "    'State_M',\n",
    "    'USER_Response_ID',\n",
    "    'successful_geocode',\n",
    "    'X',\n",
    "    'Y',\n",
    "    'citywide',\n",
    "    'district',\n",
    "    'zone',\n",
    "]\n",
    "\n",
    "\n",
    "within = [\n",
    "    col for col in reconstructed_columns\n",
    "    if col in recoded.columns\n",
    "]\n",
    "\n",
    "unbuilt = set([\n",
    "    col for col in recoded.columns\n",
    "    if (col not in within) and (col not in ignore_columns)\n",
    "])\n",
    "\n",
    "\n",
    "print(len(within))\n",
    "# GOAL: 246 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a9efef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_results = pd.DataFrame(reconstructed_columns, columns=[\"case\", \"column\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "887a83ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes, my household uses a program to help pay f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Submitting an online job application:Comfortab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Other (if you use a program not listed above t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Cleaned up or improved alley ways:In_The_Last_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Using video conferencing software (Zoom, Googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>4</td>\n",
       "      <td>From my local Community Development Organizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>4</td>\n",
       "      <td>Other:Hear_Of_Survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>4</td>\n",
       "      <td>Advanced computer skills training:Resources_Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>4</td>\n",
       "      <td>Community development organization(s):Communit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>4</td>\n",
       "      <td>Writing code:Comfortability_Using_Devices_Task</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     case                                             column\n",
       "0       4  Yes, my household uses a program to help pay f...\n",
       "2       4  Submitting an online job application:Comfortab...\n",
       "6       4  Other (if you use a program not listed above t...\n",
       "7       4  Cleaned up or improved alley ways:In_The_Last_...\n",
       "14      4  Using video conferencing software (Zoom, Googl...\n",
       "..    ...                                                ...\n",
       "238     4  From my local Community Development Organizati...\n",
       "239     4                               Other:Hear_Of_Survey\n",
       "243     4  Advanced computer skills training:Resources_Im...\n",
       "244     4  Community development organization(s):Communit...\n",
       "248     4     Writing code:Comfortability_Using_Devices_Task\n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_results[case_results[\"case\"] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cd19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a query that shows what's missing from context / primary indicators\n",
    "# What do we do with non-context primary survey answers?\n",
    "# - Can we use the value type field to capture the difference between survey questions used in NVI and\n",
    "#   survey questions that aren't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aaf60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_columns = set()\n",
    "for ind_id, indicator in indicator_map.items():\n",
    "    for i, question in indicator[\"questions\"].items():\n",
    "        indicator_columns.add((ind_id, question[\"column\"], question[\"question_id\"]))\n",
    "\n",
    "result = []\n",
    "for ind_id, col, quest_id in indicator_columns:\n",
    "    result.append(\n",
    "        recoded[col]\n",
    "        .value_counts()\n",
    "        .to_frame()\n",
    "        .reset_index()\n",
    "        .rename(columns={col: \"value\"})\n",
    "        .assign(\n",
    "            column_name=col,\n",
    "            indicator_id=ind_id,\n",
    "            question_id=quest_id,\n",
    "        )[[\"column_name\", \"value\", \"indicator_id\", \"question_id\"]]\n",
    "    )\n",
    "\n",
    "def sort_key(col):\n",
    "    \"\"\"\n",
    "    Break on the colon (or double colon) and return\n",
    "    the right most value.\n",
    "    \"\"\"\n",
    "    # If you get the 'value' col just return\n",
    "    if col.dtype == pd.Int64Dtype():\n",
    "        return col\n",
    "\n",
    "    # Flip the last and the second to last\n",
    "    filled = (\n",
    "        col.replace(\":\", \"::\")\n",
    "        .str.split(\":\", expand=True)\n",
    "        .ffill(axis=1)\n",
    "    )\n",
    "\n",
    "    return filled.iloc[:, -1] + filled.iloc[:, 0]\n",
    "\n",
    "\n",
    "pd.concat(result).sort_values([\"column_name\", \"value\"], key=sort_key).assign(\n",
    "    question_option_id=pd.NA,\n",
    ").to_csv(WORKING_DIR / \"conf\" / \"variable_questions.csv\", index=False)\n",
    "\n",
    "(\n",
    "    recoded[[\"Neighborhood_Environmental_Severity\", \"district\"]]\n",
    "    .fillna(pd.NA)\n",
    "    .groupby(\"district\")\n",
    "    .value_counts(dropna=False)\n",
    "    .reset_index(level=1)\n",
    "    .pivot(columns=\"Will_Meet_Needs_10_Years:Current_Housing\")\n",
    "    .rename(columns=lambda c: {\n",
    "        1: \"strongly_disagree\",\n",
    "        2: \"somewhat_disagree\",\n",
    "        3: \"neither_agree_nor_disagree\",\n",
    "        4: \"somewhat_agree\",\n",
    "        5: \"strongly_agree\",\n",
    "    }.get(c, 'not_answered'))\n",
    "    .fillna(0)\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .assign(\n",
    "        total=lambda df: df.sum(axis=1)\n",
    "    )\n",
    "    .astype(pd.Int64Dtype())\n",
    "    .to_csv(\"current_housing_will_meet_needs_10_yrs.csv\")\n",
    ")\n",
    "\n",
    "(\n",
    "    recoded[[\"Meets_Needs_Now:Current_Housing\", \"zone\"]]\n",
    "    .fillna(pd.NA)\n",
    "    .groupby(\"zone\")\n",
    "    .value_counts(dropna=False)\n",
    "    .reset_index(level=1)\n",
    "    .pivot(columns=\"Meets_Needs_Now:Current_Housing\")\n",
    "    .rename(columns=lambda c: {\n",
    "        1: \"strongly_disagree\",\n",
    "        2: \"somewhat_disagree\",\n",
    "        3: \"neither_agree_nor_disagree\",\n",
    "        4: \"somewhat_agree\",\n",
    "        5: \"strongly_agree\",\n",
    "    }.get(c, 'not_answered'))\n",
    "    .fillna(0)\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .assign(\n",
    "        total=lambda df: df.sum(axis=1)\n",
    "    )\n",
    "    .astype(pd.Int64Dtype())\n",
    "    .to_csv(\"current_housing_meets_needs_now.csv\", mode=\"a\")\n",
    ")\n",
    "\n",
    "\n",
    "def zebra(s):\n",
    "    # grey 2 ≈ Excel “Gray 2” = #d9d9d9\n",
    "    return ['background-color:#d9d9d9' if ((i % 2) == 0) else '' for i in range(len(s))]\n",
    "\n",
    "base   = \"font-family:'IBM Plex Sans';font-size:13pt;border:1px solid black\"\n",
    "header = base + \";font-weight:bold\"\n",
    "gray   = \"background-color:#d9d9d9\"   \n",
    "\n",
    "\n",
    "environmental_columns = [\n",
    "    col for col in recoded.columns if col.endswith(\"Neighborhood_Environmental_Severity\")\n",
    "]\n",
    "\n",
    "\n",
    "renames = {\n",
    "    0:\"Severe\",\n",
    "    1:\"Major\",\n",
    "    2:\"Moderate\",\n",
    "    3:\"Minor\",\n",
    "    4:\"Insignificant/Not a Problem\"\n",
    "}\n",
    "\n",
    "\n",
    "mode=\"w\"\n",
    "for column in environmental_columns:\n",
    "    concern, *_ = column.split(\":\")\n",
    "\n",
    "    q_table = (\n",
    "        recoded[[column, \"district\"]]\n",
    "        .fillna(pd.NA)\n",
    "        .groupby(\"district\")\n",
    "        .value_counts(dropna=False)\n",
    "        .reset_index(level=1)\n",
    "        .pivot(columns=column)\n",
    "        .rename(columns=lambda c: renames.get(c, 'not_answered'))\n",
    "        .fillna(0)\n",
    "        .droplevel(level=0, axis=1)\n",
    "        .assign(\n",
    "            total=lambda df: df.sum(axis=1)\n",
    "        )\n",
    "        .astype(pd.Int64Dtype())\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "            \"environmental_questions.xlsx\",\n",
    "            mode=mode,                 # append, don’t overwrite the file\n",
    "            engine=\"openpyxl\",        # required for append\n",
    "    ) as writer:\n",
    "        (\n",
    "            q_table\n",
    "            .style\n",
    "            .set_properties(\n",
    "                **{\n",
    "                    \"font-family\": \"IBM Plex Sans\",   # Excel falls back if font not installed\n",
    "                    \"font-size\":   \"13pt\",\n",
    "                    \"border\":      \"1px solid black\"\n",
    "                }\n",
    "            )\n",
    "            .apply(zebra)                 # alternating row shade\n",
    "            .apply_index(lambda s: [header]*len(s), axis=\"columns\")  # column headers\n",
    "            .apply_index(lambda s: [base]*len(s),   axis=\"index\")    # row index cells\n",
    "            .set_table_styles(\n",
    "                [\n",
    "                    {\n",
    "                        \"selector\": \"th\",\n",
    "                        \"props\": [(\"font-weight\", \"bold\"), (\"border\", \"1px solid black\")]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            .to_excel(writer, sheet_name=concern, index=False)\n",
    "        )\n",
    "\n",
    "        ws = writer.sheets[concern]                 # openpyxl worksheet\n",
    "\n",
    "        for idx, col in enumerate(ws.iter_cols(values_only=True), start=1):\n",
    "            if idx == 1:\n",
    "                continue\n",
    "            max_len = max(len(str(v)) if v is not None else 0 for v in col + (ws.cell(1, idx).value,))\n",
    "            # Excel’s unit ≈ character width; add a little padding\n",
    "            ws.column_dimensions[get_column_letter(idx)].width = 25\n",
    "        \n",
    "        mode = \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    normalized_data_dictionary\n",
    "    .reset_index()\n",
    "    .drop(\"index\", axis=1)\n",
    "    .style\n",
    "    .set_properties(\n",
    "        **{\n",
    "            \"font-family\": \"IBM Plex Sans\",   # Excel falls back if font not installed\n",
    "            \"font-size\":   \"13pt\",\n",
    "            \"border\":      \"1px solid black\"\n",
    "        }\n",
    "    )\n",
    "    .apply(zebra)                 # alternating row shade\n",
    "    .apply_index(lambda s: [header]*len(s), axis=\"columns\")  # column headers\n",
    "    .apply_index(lambda s: [base]*len(s),   axis=\"index\")    # row index cells\n",
    "    .set_table_styles(\n",
    "        [\n",
    "            {\n",
    "                \"selector\": \"th\",\n",
    "                \"props\": [(\"font-weight\", \"bold\"), (\"border\", \"1px solid black\")]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    .to_excel(\"normalized_data_dict.xlsx\", sheet_name=\"dictionary\", index=False)\n",
    ")\n",
    "\n",
    "\n",
    "col_ref = pd.read_excel(Path.cwd().parent.parent / \"survey_col_reference.xlsx\")\n",
    "\n",
    "result = []\n",
    "for i, row in col_ref.dropna().iterrows():\n",
    "    column_names = row[\"Question Alias\"].split(\"\\n\")\n",
    "    answers = row[\"Response Options and Coding\"].split(\"\\n\")\n",
    "\n",
    "    groups = []\n",
    "    questions = []\n",
    "    for col_name in column_names:\n",
    "        q, *group = col_name.replace(\"::\", \":\").split(\":\")\n",
    "\n",
    "        if group: \n",
    "            groups.append(group[0])\n",
    "        else:\n",
    "            groups.append(\"\")\n",
    "\n",
    "        questions.append(q)\n",
    "\n",
    "    codes = []\n",
    "    text_values = []\n",
    "    for answer in answers:\n",
    "        *code, text_val = answer.split(\"=\")\n",
    "\n",
    "        if code:\n",
    "            codes.append(code[0])\n",
    "        else:\n",
    "            codes.append(None)\n",
    "\n",
    "        text_values.append(text_val)\n",
    "\n",
    "    group_out = []\n",
    "    question_out = []\n",
    "    answer_out = []\n",
    "    code_out = []\n",
    "    for group, question in zip(groups, questions):\n",
    "        for code, text_val in zip(codes, text_values):\n",
    "            group_out.append(group)\n",
    "            question_out.append(question)\n",
    "            answer_out.append(text_val)\n",
    "            code_out.append(code)\n",
    "\n",
    "    result.append(pd.DataFrame(\n",
    "        {\n",
    "            \"group\": group_out,\n",
    "            \"question\": question_out,\n",
    "            \"answer\": answer_out,\n",
    "            \"code\": code_out\n",
    "        }\n",
    "    ))\n",
    "\n",
    "normalized_data_dictionary = pd.concat(result)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "tabulate_info = pd.read_excel(\"normalized_data_dict.xlsx\")\n",
    "\n",
    "def slugify(txt: str) -> str:\n",
    "    return re.sub(r'[^a-z0-9]+', '_', txt.lower()).strip('_')\n",
    "\n",
    "\n",
    "output_tables = []\n",
    "counter = 0\n",
    "for (q_group, question), rows in tabulate_info.fillna(\"\").groupby([\"group\", \"question\"]):\n",
    "    data_column = question + \":\" + q_group if q_group else question\n",
    "\n",
    "    if data_column not in recoded.columns:\n",
    "        print(data_column)\n",
    "        continue\n",
    "\n",
    "    renames = {\n",
    "        int(item[\"code\"]): item[\"answer\"] for _, item in rows.iterrows() if item[\"code\"]\n",
    "    }\n",
    "\n",
    "    q_table = (\n",
    "        recoded[[data_column, \"district\"]]\n",
    "        .fillna(pd.NA)\n",
    "        .groupby(\"district\")\n",
    "        .value_counts(dropna=False)\n",
    "        .reset_index(level=1)\n",
    "        .pivot(columns=data_column)\n",
    "        .rename(columns=lambda c: renames.get(c, 'not_answered'))\n",
    "        .fillna(0)\n",
    "        .droplevel(level=0, axis=1)\n",
    "        .assign(\n",
    "            total=lambda df: df.sum(axis=1)\n",
    "        )\n",
    "        .astype(pd.Int64Dtype())\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    q_table.to_csv(\n",
    "        Path.home() / \n",
    "        \"Desktop\" / \n",
    "        \"1_projects\" / \n",
    "        \"nvi_districts_tabulated\" / \n",
    "        f\"{slugify(q_group)}_{slugify(question)}.csv\"\n",
    "    )\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "def expected_values(table):\n",
    "    expected_values = (\n",
    "        (\n",
    "            table.sum(axis=1) \n",
    "            / table.sum().sum()\n",
    "        ).values.reshape(-1, 1)\n",
    "        * (\n",
    "            table.sum(axis=0)\n",
    "        ).values\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(expected_values, index=table.index, columns=table.columns).round(2)\n",
    "\n",
    "\n",
    "group_cols = [\n",
    "    \"Age\", \n",
    "    \"General distrust of law enforcement:Hesitate_Reporting_Crime_Reason\"\n",
    "]\n",
    "\n",
    "recodes = {\n",
    "    1: \"General distrust of law enforcement\",\n",
    "    2: \"Concern that I won’t be taken seriously, or no action will be taken \",\n",
    "    3: \"Fear of retaliation\",\n",
    "    4: \"Risk of consequences from immigration (such as deportation)\",\n",
    "    5: \"Text Entry\",\n",
    "    6: \"I would not hesitate or avoid reporting crime \",\n",
    "}\n",
    "\n",
    "renames = {\n",
    "    1: \"18-24\",\n",
    "    2: \"25-34\",\n",
    "    3: \"35-44\",\n",
    "    4: \"45-54\",\n",
    "    5: \"55-64\",\n",
    "    6: \"65+\",\n",
    "    7: \"Prefers not to answer age\",\n",
    "}\n",
    "\n",
    "coding_crosstab = (\n",
    "    recoded[group_cols]\n",
    "    .value_counts(dropna=False)\n",
    "    .reset_index()\n",
    "    .pivot(\n",
    "        index=group_cols[1], \n",
    "        columns=group_cols[0], \n",
    "        values=\"count\"\n",
    "    )\n",
    "    .rename(columns=lambda c: renames.get(c, 'not_answered_crime'))\n",
    "    .reset_index()\n",
    "    .pipe(\n",
    "        lambda d: d.assign(\n",
    "            concerns_reporting_crime=d[group_cols[1]].map(\n",
    "                lambda v: recodes.get(v, \"Option Not selected\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .drop(group_cols[1], axis=1)\n",
    "    .drop(\"not_answered_crime\", axis=1)\n",
    "    .set_index(\"concerns_reporting_crime\")\n",
    ")\n",
    "\n",
    "\n",
    "aggregation_categories = [\n",
    "    \"citywide\",\n",
    "    \"district\",\n",
    "    \"zone\"\n",
    "]\n",
    "\n",
    "columns = pd.read_excel(Path.cwd() / \"normalized_data_dict.xlsx\")\n",
    "aggregate_to = \"Age\"\n",
    "\n",
    "aggregate_rename = {\n",
    "    row[\"code\"]: row[\"answer\"] for _, row in\n",
    "    columns[columns[\"question\"] == aggregate_to].iterrows()\n",
    "}\n",
    "\n",
    "groups = []\n",
    "for (group, multiselect), rows in columns.groupby([\"group\", \"multiselect\"]):\n",
    "    if not group:\n",
    "        ...\n",
    "\n",
    "    elif multiselect:\n",
    "        questions = [col for col in recoded if col.endswith(group)]\n",
    "        renames = {col: col.split(\":\")[0] for col in questions}\n",
    "        groups.append((recoded[[aggregate_to] + questions].rename(columns=renames).copy(), list(renames.values())))\n",
    "    \n",
    "    else:\n",
    "        print(group)\n",
    "\n",
    "\n",
    "df, questions = groups[0]\n",
    "df[questions] = ~df[questions].isna()\n",
    "\n",
    "aggregated = pd.concat([\n",
    "    df.groupby(\"Age\", dropna=False).aggregate(\"sum\"),\n",
    "    df[\"Age\"].value_counts(dropna=False).rename(\"Total in Aggregation Group\"),\n",
    "], axis=1)\n",
    "\n",
    "aggregated.T.rename(columns=lambda v: aggregate_rename.get(v, \"No Answer Provided\")).T\n",
    "\n",
    "\n",
    "grid_of_death = pd.read_excel(Path.cwd().parent.parent / \"grid_of_death.xlsx\")\n",
    "\n",
    "result = []\n",
    "for i, row in grid_of_death.iterrows():\n",
    "    columns = row[\"column_name\"].split(\"\\n\")\n",
    "    answers = row[\"answer\"].split(\"\\n\")\n",
    "\n",
    "    for col, ans in zip(columns, answers):\n",
    "        answer_left, question, group = col.split(\":\")\n",
    "        code, answer_right = ans.split(\"=\")\n",
    "\n",
    "        if answer_left != answer_right:\n",
    "            print(f\"{answer_left} != {answer_right}\")\n",
    "\n",
    "        result.append({\n",
    "            \"group\": group,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer_right,\n",
    "            \"code\": code,\n",
    "        })\n",
    "\n",
    "pd.DataFrame(result).to_excel(\"grid_of_life.xlsx\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
